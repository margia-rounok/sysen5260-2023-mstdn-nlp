version: '2'

services:
  spark-master:
    user: root
    working_dir: /opt/spark
    image: apache/spark-py:v3.4.0
    environment:
      - SPARK_NO_DAEMONIZE=true
    volumes:
      - datalake:/opt/data
      - warehouse:/opt/warehouse
    ports:
      - '7077:7077'
      - '8080:8080'
    command: ./sbin/start-master.sh
  spark-worker:
    user: root
    working_dir: /opt/spark
    image: apache/spark-py:v3.4.0
    ports:
      - '8081:8081'
    environment:
      - SPARK_NO_DAEMONIZE=true
      - "SPARK_MASTER=spark://spark-master:7077"
    volumes:
      - datalake:/opt/data
      - warehouse:/opt/warehouse
    command: ./sbin/start-worker.sh spark://spark-master:7077 
  spark-driver:
    user: root
    working_dir: /opt/app
    build:
      context: ./spark_code_new
    environment:
      - PYTHONPATH=/opt/spark/python:/opt/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/app/
    volumes:
      - datalake:/opt/data
      - warehouse:/opt/warehouse

  rest:
    user: root
    build:
      context: ./rest
    environment:
      - PYTHONPATH=/opt/spark/python:/opt/spark/python/lib/py4j-0.10.9.7-src.zip:/opt/app/
    volumes:
      - warehouse:/opt/warehouse
      - ./rest:/opt/app   ## uncomment for rapid development.
    ports:
      - '8000:8000'
  jupyter:
    user: root
    working_dir: /opt/spark
    build: 
      context: ./jupyter
    volumes:
      - ./spark_code_new:/opt/spark/sparkcode
      - datalake:/opt/data
      - warehouse:/opt/warehouse
    environment:
      - PYTHONPATH=/opt/spark/python:/opt/spark/python/lib/py4j-0.10.9.7-src.zip
    ports:
      - '8888:8888'
    command: jupyter lab --allow-root --NotebookApp.token=secret123 --ip 0.0.0.0 --no-browser

  extractor:
    user: root
    build: 
      context: ./extractor
    environment:
      PYTHONUNBUFFERED: 1   # Make python flush its print-buffer so we can see progress msgs    volumes:
    volumes:
      - datalake:/opt/data
  
volumes:
  datalake:
  warehouse:

